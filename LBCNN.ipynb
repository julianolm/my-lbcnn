{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "LBCNN_1.0.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/julianolm/Local-Binary-Convolutional-Neural-Network/blob/main/LBCNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J2j38j246Ko2"
      },
      "source": [
        "# Implementation of LBCNN and application on CIFAR-10"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6m8l8uxZwMMB",
        "outputId": "260082ca-a0c6-43bb-a9ef-2329f06841de"
      },
      "source": [
        "%matplotlib inline\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "torch.set_printoptions(edgeitems=2, linewidth=75)\n",
        "torch.manual_seed(123)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7f42028f68f0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b7HdDKDSwMEN"
      },
      "source": [
        "import torch.nn as nn\n",
        "from torchvision import datasets, transforms\n",
        "import torch.nn.functional as F"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vopdwl0SOQBB",
        "outputId": "28e73652-6f0e-4fa5-cb95-7758435dbb0f"
      },
      "source": [
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "print(f'Training on device {device}.')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training on device cuda.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rtKtxGwHAd-x"
      },
      "source": [
        "## Preparing the Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kTAH2eqf6QJp",
        "outputId": "b276f662-2b76-4cbb-91f7-b7a12f59f3d4"
      },
      "source": [
        "transform_train = transforms.Compose([\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "])\n",
        "\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "])\n",
        "\n",
        "cifar10 = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)\n",
        "cifar10_val = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(cifar10, batch_size=64, shuffle=True)\n",
        "val_loader = torch.utils.data.DataLoader(cifar10_val, batch_size=32, shuffle=False)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "46wt4lE_eqiT"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vB5f7AqF-vW1"
      },
      "source": [
        "def new_kernel(in_channels=384, inter_channels=512, sparsity=0.1):\n",
        "    \"\"\"\n",
        "        Returns the anchor weights for a layer with \"in_channels\" in channels and one output channel.\n",
        "    \"\"\"\n",
        "    from random import randint\n",
        "    from math import ceil\n",
        "\n",
        "    nk = np.zeros((inter_channels, in_channels*3*3))\n",
        "    for out in range(inter_channels):\n",
        "        for i in range(ceil(in_channels*3*3*sparsity)):\n",
        "            a = randint(0,in_channels*3*3 - 1)\n",
        "            nk[out, a] = 1 if randint(1,2)==1 else -1\n",
        "\n",
        "    nk = nk.reshape(inter_channels, in_channels, 3, 3)\n",
        "    return nk"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gi0f8Zw5KMds"
      },
      "source": [
        "class LBCBlock(nn.Module):\n",
        "    def __init__(self, n_channels=384, n_kernels=512, sparsity=0.1):\n",
        "        super().__init__()\n",
        "        self.n_channels = n_channels\n",
        "        self.n_kernels = n_kernels\n",
        "        self.Batch_Norm = nn.BatchNorm2d(n_channels)\n",
        "\n",
        "        self.conv_filter = nn.Conv2d(n_channels, n_kernels, kernel_size=3, padding=1, bias=False)\n",
        "        kernels = torch.tensor(new_kernel(n_channels, n_kernels, sparsity)).type('torch.FloatTensor')\n",
        "        self.conv_filter.weight = nn.Parameter(kernels, requires_grad=False)\n",
        "\n",
        "        self.weighted_sum = nn.Conv2d(n_kernels, n_channels, kernel_size=1, bias=False)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.Batch_Norm(x)\n",
        "        with torch.no_grad():\n",
        "            out = torch.relu(self.conv_filter(out))\n",
        "        out = self.weighted_sum(out)\n",
        "        out += x\n",
        "\n",
        "        return out"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JnLTHZvYKOV3"
      },
      "source": [
        "img_width = 32\n",
        "img_height = 32\n",
        "\n",
        "class NetLBC(nn.Module):\n",
        "    def __init__(self, lbc_filters=512, n_channels=384, n_blocks=10, sparsity=0.1, hidden_units=384):\n",
        "        super().__init__()\n",
        "        self.n_channels = n_channels\n",
        "        self.n_blocks = n_blocks\n",
        "        self.hidden_units = hidden_units\n",
        "\n",
        "        self.conv1 = nn.Conv2d(3, n_channels, kernel_size=3, padding=1)\n",
        "        \n",
        "        from collections import OrderedDict\n",
        "        self.lbc_blocks = nn.Sequential(\n",
        "            OrderedDict([\n",
        "                         (f'lbc_block_{i}', LBCBlock(n_channels, lbc_filters, sparsity)) for i in range(1,n_blocks+1) \n",
        "                         ])\n",
        "            )\n",
        "\n",
        "        self.fc1 = nn.Linear(self.n_channels * 6 * 6, self.hidden_units)                                      \n",
        "        self.fc2 = nn.Linear(self.hidden_units, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.conv1(x)\n",
        "        out = self.lbc_blocks(out)\n",
        "        out = torch.nn.functional.max_pool2d(out, kernel_size=6,padding=2)                      \n",
        "        \n",
        "        out = out.view(-1, self.n_channels * 6 * 6)                                             \n",
        "\n",
        "        out = torch.relu(self.fc1(out))\n",
        "        out = self.fc2(out)\n",
        "\n",
        "        return out"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p5liaDpgVgxh"
      },
      "source": [
        "## Training and validating functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j-3X9S1droJ_"
      },
      "source": [
        "from datetime import datetime as datetime\n",
        "\n",
        "def training_loop(n_epochs, model, loss_fn, train_loader, optimizer, scheduler=None):\n",
        "    for epoch in range(1, n_epochs+1):\n",
        "        train_loss = 0\n",
        "        iter = 0\n",
        "        for imgs, labels in train_loader:\n",
        "            imgs = imgs.to(device=device)\n",
        "            labels = labels.to(device=device)\n",
        "            out = model(imgs)\n",
        "            loss = loss_fn(out, labels)\n",
        "\n",
        "            train_loss += loss.item()\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "\n",
        "            optimizer.step()\n",
        "            \n",
        "            iter += 1\n",
        "\n",
        "        if scheduler is not None:\n",
        "            scheduler.step()\n",
        "\n",
        "        print(\"%s Epoch: %d, Loss: %f\" % (datetime.now(), epoch, train_loss/len(train_loader)))"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qVDjMbP8roHq"
      },
      "source": [
        "def validate(model, train_loader, val_loader):\n",
        "    for season, loader in [('Train', train_loader), ('Validation', val_loader)]:\n",
        "        total = 0\n",
        "        correct = 0\n",
        "        for imgs, labels in loader:\n",
        "            imgs = imgs.to(device=device)\n",
        "            labels = labels.to(device=device)\n",
        "            with torch.no_grad():\n",
        "                out = model(imgs)\n",
        "                _, pred = torch.max(out, dim=1)\n",
        "\n",
        "                total += imgs.shape[0]\n",
        "                correct += int((pred == labels).sum())\n",
        "\n",
        "        print(\"%s accuracy: %f\" % (season, correct/total*100))"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ign1htT4V-KG"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ADuqkzg08BKq"
      },
      "source": [
        "model = NetLBC(lbc_filters=512, n_channels=16, n_blocks=10, sparsity=0.1, hidden_units=384).to(device=device)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tg8zZiRVuf_7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d434948c-13e1-4b04-a3db-eb5733d97e51"
      },
      "source": [
        "validate(model, train_loader, val_loader)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train accuracy: 10.854000\n",
            "Validation accuracy: 10.380000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SGwG0tu0KnoR"
      },
      "source": [
        "loss = nn.CrossEntropyLoss()\n",
        "learnable_parameters = []\n",
        "for _, param in model.named_parameters():\n",
        "    learnable_parameters.append(param)\n",
        "optimizer = torch.optim.SGD(params=learnable_parameters, lr=1e-4, momentum=0.9, weight_decay=5e-4)\n",
        "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=200)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QcSzNC0crn-H"
      },
      "source": [
        "training_loop(n_epochs=270,\n",
        "              model=model,\n",
        "              loss_fn=loss,\n",
        "              train_loader=train_loader,\n",
        "              optimizer=optimizer,\n",
        "              scheduler=scheduler)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CTbkE58qVAtl"
      },
      "source": [
        "Have already trained and saved the model, so just I'm just showing the results here. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wSFE0KG4UYiF",
        "outputId": "60a27f59-1ef0-49d1-a4dc-b872813879ef"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9cPWzoygUalK",
        "outputId": "719c7469-8e2e-4952-e46e-4d17f0052b80"
      },
      "source": [
        "model.load_state_dict(torch.load('/content/drive/MyDrive/LBCNN_1.1.pt'))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9wjDkPN9SIXK",
        "outputId": "a06bfc0c-d8a5-49f2-9618-e8ae26837353"
      },
      "source": [
        "validate(model, train_loader, val_loader)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train accuracy: 91.330000\n",
            "Validation accuracy: 79.230000\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}